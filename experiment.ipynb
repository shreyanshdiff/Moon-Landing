{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for AAPL...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'REST' object has no attribute 'get_barset'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 108\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# Run the bot\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 108\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 97\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFetching data for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymbol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 97\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43msymbol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerforming feature engineering...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     99\u001b[0m     data \u001b[38;5;241m=\u001b[39m feature_engineering(data)\n",
      "Cell \u001b[1;32mIn[1], line 24\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(symbol, days)\u001b[0m\n\u001b[0;32m     22\u001b[0m end_date \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[0;32m     23\u001b[0m start_date \u001b[38;5;241m=\u001b[39m end_date \u001b[38;5;241m-\u001b[39m timedelta(days\u001b[38;5;241m=\u001b[39mdays)\n\u001b[1;32m---> 24\u001b[0m barset \u001b[38;5;241m=\u001b[39m \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_barset\u001b[49m(symbol, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mday\u001b[39m\u001b[38;5;124m'\u001b[39m, start\u001b[38;5;241m=\u001b[39mstart_date, end\u001b[38;5;241m=\u001b[39mend_date)\n\u001b[0;32m     25\u001b[0m df \u001b[38;5;241m=\u001b[39m barset[symbol]\n\u001b[0;32m     26\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m: [bar\u001b[38;5;241m.\u001b[39mt\u001b[38;5;241m.\u001b[39mtimestamp() \u001b[38;5;28;01mfor\u001b[39;00m bar \u001b[38;5;129;01min\u001b[39;00m df],\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopen\u001b[39m\u001b[38;5;124m'\u001b[39m: [bar\u001b[38;5;241m.\u001b[39mo \u001b[38;5;28;01mfor\u001b[39;00m bar \u001b[38;5;129;01min\u001b[39;00m df],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume\u001b[39m\u001b[38;5;124m'\u001b[39m: [bar\u001b[38;5;241m.\u001b[39mv \u001b[38;5;28;01mfor\u001b[39;00m bar \u001b[38;5;129;01min\u001b[39;00m df],\n\u001b[0;32m     33\u001b[0m })\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'REST' object has no attribute 'get_barset'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import alpaca_trade_api as tradeapi\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Alpaca API keys (replace with your keys)\n",
    "API_KEY = 'PKA8CAYXHIJZVP6N16Y3'\n",
    "API_SECRET = 'UfbITIZ9N3hPnoppHda2HjfFBkPom'\n",
    "BASE_URL = 'https://paper-api.alpaca.markets'  # Paper trading URL\n",
    "\n",
    "# Initialize Alpaca API\n",
    "api = tradeapi.REST(API_KEY, API_SECRET, BASE_URL, api_version='v2')\n",
    "\n",
    "# Define the stock symbol to trade (e.g., Apple)\n",
    "symbol = 'AAPL'\n",
    "\n",
    "# Fetch historical data (past 100 days)\n",
    "def get_data(symbol, days=100):\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=days)\n",
    "    barset = api.get_barset(symbol, 'day', start=start_date, end=end_date)\n",
    "    df = barset[symbol]\n",
    "    df = pd.DataFrame({\n",
    "        'timestamp': [bar.t.timestamp() for bar in df],\n",
    "        'open': [bar.o for bar in df],\n",
    "        'high': [bar.h for bar in df],\n",
    "        'low': [bar.l for bar in df],\n",
    "        'close': [bar.c for bar in df],\n",
    "        'volume': [bar.v for bar in df],\n",
    "    })\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "    return df\n",
    "\n",
    "# Feature engineering: Creating simple features like moving averages\n",
    "def feature_engineering(df):\n",
    "    df['SMA_20'] = df['close'].rolling(window=20).mean()\n",
    "    df['SMA_50'] = df['close'].rolling(window=50).mean()\n",
    "    df['RSI'] = 100 - (100 / (1 + df['close'].pct_change().rolling(window=14).mean() / df['close'].pct_change().rolling(window=14).std()))\n",
    "    df['target'] = np.where(df['close'].shift(-1) > df['close'], 1, 0)  # 1 for buy, 0 for hold/sell\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "# Train a machine learning model\n",
    "def train_model(df):\n",
    "    X = df[['SMA_20', 'SMA_50', 'RSI']]\n",
    "    y = df['target']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f'Model Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "    return model\n",
    "\n",
    "# Execute a trade (buy/sell)\n",
    "def execute_trade(model, df, symbol):\n",
    "    # Get the latest data point\n",
    "    last_data = df.iloc[-1]\n",
    "    X_latest = last_data[['SMA_20', 'SMA_50', 'RSI']].values.reshape(1, -1)\n",
    "    \n",
    "    # Predict the action\n",
    "    action = model.predict(X_latest)[0]\n",
    "    \n",
    "    # Get the current account balance\n",
    "    account = api.get_account()\n",
    "    cash = float(account.cash)\n",
    "    \n",
    "    if action == 1 and cash > 10:  # Buy if predicted 1 (buy) and have enough cash\n",
    "        print(f\"Buying {symbol}...\")\n",
    "        api.submit_order(\n",
    "            symbol=symbol,\n",
    "            qty=1,  # Number of shares\n",
    "            side='buy',\n",
    "            type='market',\n",
    "            time_in_force='gtc'  # Good till cancelled\n",
    "        )\n",
    "    elif action == 0:  # Sell if predicted 0 (hold/sell)\n",
    "        print(f\"Selling {symbol}...\")\n",
    "        positions = api.list_positions()\n",
    "        for position in positions:\n",
    "            if position.symbol == symbol:\n",
    "                qty = int(position.qty)\n",
    "                if qty > 0:\n",
    "                    api.submit_order(\n",
    "                        symbol=symbol,\n",
    "                        qty=qty,\n",
    "                        side='sell',\n",
    "                        type='market',\n",
    "                        time_in_force='gtc'\n",
    "                    )\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    print(f\"Fetching data for {symbol}...\")\n",
    "    data = get_data(symbol)\n",
    "    print(\"Performing feature engineering...\")\n",
    "    data = feature_engineering(data)\n",
    "    print(\"Training model...\")\n",
    "    model = train_model(data)\n",
    "    \n",
    "    # Execute trade based on the model's prediction\n",
    "    execute_trade(model, data, symbol)\n",
    "\n",
    "# Run the bot\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 73\u001b[0m\n\u001b[0;32m     70\u001b[0m     execute_trade(model, data, symbol)\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstock_model.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m , \u001b[43mmodel\u001b[49m)\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# Run the bot\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the stock symbol to trade (e.g., Apple)\n",
    "symbol = 'AAPL'\n",
    "\n",
    "# Fetch historical data using Yahoo Finance (past 100 days)\n",
    "def get_data(symbol, days=100):\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=days)\n",
    "    \n",
    "    # Download historical data\n",
    "    data = yf.download(symbol, start=start_date, end=end_date, interval=\"1d\")\n",
    "    \n",
    "    # Reset the index to get 'Date' as a column\n",
    "    data.reset_index(inplace=True)\n",
    "    \n",
    "    # Rename columns for consistency with your original code\n",
    "    data = data[['Date', 'Open', 'High', 'Low', 'Close', 'Volume']]\n",
    "    data.columns = ['timestamp', 'open', 'high', 'low', 'close', 'volume']\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Feature engineering: Creating simple features like moving averages\n",
    "def feature_engineering(df):\n",
    "    df['SMA_20'] = df['close'].rolling(window=20).mean()\n",
    "    df['SMA_50'] = df['close'].rolling(window=50).mean()\n",
    "    df['RSI'] = 100 - (100 / (1 + df['close'].pct_change().rolling(window=14).mean() / df['close'].pct_change().rolling(window=14).std()))\n",
    "    df['target'] = np.where(df['close'].shift(-1) > df['close'], 1, 0)  # 1 for buy, 0 for hold/sell\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "# Train a machine learning model\n",
    "def train_model(df):\n",
    "    X = df[['SMA_20', 'SMA_50', 'RSI']]\n",
    "    y = df['target']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f'Model Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "    return model\n",
    "\n",
    "# Execute a trade (buy/sell)\n",
    "def execute_trade(model, df, symbol):\n",
    "    # Get the latest data point\n",
    "    last_data = df.iloc[-1]\n",
    "    X_latest = last_data[['SMA_20', 'SMA_50', 'RSI']].values.reshape(1, -1)\n",
    "    \n",
    "    # Predict the action\n",
    "    action = model.predict(X_latest)[0]\n",
    "    \n",
    "    # Simulating the trade process (as Alpaca API is unavailable)\n",
    "    if action == 1:  # Buy if predicted 1 (buy)\n",
    "        print(f\"Buying {symbol}...\")\n",
    "    elif action == 0:  # Sell if predicted 0 (hold/sell)\n",
    "        print(f\"Selling {symbol}...\")\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    print(f\"Fetching data for {symbol}...\")\n",
    "    data = get_data(symbol)\n",
    "    print(\"Performing feature engineering...\")\n",
    "    data = feature_engineering(data)\n",
    "    print(\"Training model...\")\n",
    "    model = train_model(data)\n",
    "    \n",
    "    # Save the model using joblib\n",
    "    joblib.dump(model, 'stock_trading_model.pkl')\n",
    "    print(\"Model saved successfully!\")\n",
    "    \n",
    "    # Execute trade based on the model's prediction\n",
    "    execute_trade(model, data, symbol)\n",
    "\n",
    "# Run the bot\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for AAPL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "c:\\Users\\Shreyansh Singh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing feature engineering...\n",
      "Training model...\n",
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.7647 - loss: 9.2100 - val_accuracy: 0.8000 - val_loss: 6.8490\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.7059 - loss: 10.5768 - val_accuracy: 0.8000 - val_loss: 5.6088\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.7647 - loss: 4.7220 - val_accuracy: 0.8000 - val_loss: 4.4114\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.7059 - loss: 5.1251 - val_accuracy: 0.8000 - val_loss: 3.2541\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.5294 - loss: 6.4977 - val_accuracy: 0.8000 - val_loss: 2.1345\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.5882 - loss: 6.5738 - val_accuracy: 0.8000 - val_loss: 1.1056\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.5294 - loss: 4.5638 - val_accuracy: 0.2000 - val_loss: 1.0330\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.6471 - loss: 3.6536 - val_accuracy: 0.4000 - val_loss: 1.5533\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.3529 - loss: 7.0606 - val_accuracy: 0.2000 - val_loss: 1.8537\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.6471 - loss: 3.6511 - val_accuracy: 0.2000 - val_loss: 1.6121\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Model Accuracy: 0.2\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "-1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Shreyansh Singh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: -1",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 107\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;66;03m# Run the bot\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 107\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 102\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     99\u001b[0m model \u001b[38;5;241m=\u001b[39m train_model(data)\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# Execute trade based on the model's prediction\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m \u001b[43mexecute_trade\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msymbol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstock_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 71\u001b[0m, in \u001b[0;36mexecute_trade\u001b[1;34m(model, data, symbol)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute_trade\u001b[39m(model, data, symbol):\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;66;03m# Prepare the latest data for prediction (ensure proper shape and dtype)\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m     X_latest \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSMA_20\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSMA_50\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRSI\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mvalues  \u001b[38;5;66;03m# Adjust to your data format\u001b[39;00m\n\u001b[0;32m     72\u001b[0m     X_latest \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(X_latest, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;66;03m# Ensure it's in the correct shape for prediction (1 sample, n features)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Shreyansh Singh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\Shreyansh Singh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: -1"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# Define the stock symbol to trade (e.g., Apple)\n",
    "symbol = 'AAPL'\n",
    "\n",
    "# Fetch historical data using Yahoo Finance (past 100 days)\n",
    "def get_data(symbol, days=100):\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=days)\n",
    "    \n",
    "    # Download historical data\n",
    "    data = yf.download(symbol, start=start_date, end=end_date, interval=\"1d\")\n",
    "    \n",
    "    # Reset the index to get 'Date' as a column\n",
    "    data.reset_index(inplace=True)\n",
    "    \n",
    "    # Rename columns for consistency with your original code\n",
    "    data = data[['Date', 'Open', 'High', 'Low', 'Close', 'Volume']]\n",
    "    data.columns = ['timestamp', 'open', 'high', 'low', 'close', 'volume']\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Feature engineering: Creating simple features like moving averages\n",
    "def feature_engineering(df):\n",
    "    df['SMA_20'] = df['close'].rolling(window=20).mean()\n",
    "    df['SMA_50'] = df['close'].rolling(window=50).mean()\n",
    "    df['RSI'] = 100 - (100 / (1 + df['close'].pct_change().rolling(window=14).mean() / df['close'].pct_change().rolling(window=14).std()))\n",
    "    df['target'] = np.where(df['close'].shift(-1) > df['close'], 1, 0)  # 1 for buy, 0 for hold/sell\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "# Train a deep learning model\n",
    "def train_model(df):\n",
    "    # Feature and target variables\n",
    "    X = df[['SMA_20', 'SMA_50', 'RSI']]\n",
    "    y = df['target']\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Build a simple neural network model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Sigmoid for binary classification (buy/sell)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "    \n",
    "    # Evaluate the model\n",
    "    y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "    print(f'Model Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Execute a trade (buy/sell)\n",
    "def execute_trade(model, data, symbol):\n",
    "    # Prepare the latest data for prediction (ensure proper shape and dtype)\n",
    "    X_latest = data[-1][['SMA_20', 'SMA_50', 'RSI']].values  # Adjust to your data format\n",
    "    X_latest = np.array(X_latest, dtype=np.float32)\n",
    "\n",
    "    # Ensure it's in the correct shape for prediction (1 sample, n features)\n",
    "    if X_latest.ndim == 1:\n",
    "        X_latest = X_latest.reshape(1, -1)\n",
    "\n",
    "    print(f\"X_latest shape: {X_latest.shape}\")\n",
    "\n",
    "    # Predict the action: 1 = buy, 0 = hold/sell\n",
    "    prediction = model.predict(X_latest)\n",
    "    action = (prediction > 0.5).astype(int)[0][0]\n",
    "\n",
    "    print(f\"Predicted action: {action}\")\n",
    "\n",
    "    # Execute trade based on the action\n",
    "    if action == 1:\n",
    "        print(f\"Executing Buy order for {symbol}\")\n",
    "        # Execute Buy logic here\n",
    "    else:\n",
    "        print(f\"Executing Sell/Hold order for {symbol}\")\n",
    "# Main function\n",
    "def main():\n",
    "    print(f\"Fetching data for {symbol}...\")\n",
    "    data = get_data(symbol)\n",
    "    print(\"Performing feature engineering...\")\n",
    "    data = feature_engineering(data)\n",
    "    print(\"Training model...\")\n",
    "    model = train_model(data)\n",
    "    \n",
    "    # Execute trade based on the model's prediction\n",
    "    execute_trade(model, data, symbol)\n",
    "    model.save('stock_model.h5')\n",
    "\n",
    "# Run the bot\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
